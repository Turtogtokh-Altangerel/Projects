from PIL import Image
import os
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, BatchNormalization
from sklearn.model_selection import train_test_split
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

#Choosing the size of input images.
h = 128
w = 128

#loading prepared samples.
train_img_list = np.load("img_list.npy")
labels = np.load("labels.npy")
#spliiting the dataset for training and testing.
train_x, test_x, train_y, test_y = train_test_split(np.asarray(train_img_list), np.asarray(labels), test_size=0.3, random_state=25)


print(f"No. of training samples: {train_x.shape[0]}")
print(f"No. of testing samples: {test_x.shape[0]}")
print(f"No. of training samples: {train_y.shape[0]}")
print(f"No. of testing samples: {test_y.shape[0]}")


#CNN model configuration.
input_shape = (h, w, 1)
model = Sequential()
#Conv2D Layers
model.add(Conv2D(12, (64, 64), padding='same',input_shape=input_shape, activation = 'relu'))
model.add(Conv2D(12, (64, 64), activation = 'relu'))
model.add(BatchNormalization())
#Max Pooling Layer
model.add(MaxPooling2D(pool_size=(2, 2)))
#Conv2D Layers
model.add(Conv2D(12, (25, 25), padding='same', activation = 'relu'))
model.add(Conv2D(12, (25, 25), activation = 'relu'))
model.add(BatchNormalization())
#Max Pooling
model.add(MaxPooling2D(pool_size=(2, 2)))
#Flattening Layer
model.add(Flatten())
#Dense Layer
model.add(Dense(96, activation = 'relu'))
model.add(Dense(1, activation = 'sigmoid'))


#compiling the model.
model.compile(optimizer='adam', 
              loss='binary_crossentropy', 
              metrics=['binary_accuracy'])

model.summary()

#training the model.
model.fit(train_x, train_y,
              epochs = 15,
              validation_split=0.2,
              shuffle = True)


#testing the model with test dataset.
model.evaluate(test_x, test_y)

#saving the model.
model.save("model2.h5")